{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "документация: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n",
    "\n",
    "примеры: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import cross_validation, datasets, metrics, tree ,ensemble\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_problem = datasets.make_classification(n_features = 2, n_informative = 2, \n",
    "                                                      n_classes = 3, n_redundant=0, \n",
    "                                                      n_clusters_per_class=1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ListedColormap(['red', 'blue', 'yellow'])\n",
    "light_colors = ListedColormap(['lightcoral', 'lightblue', 'lightyellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.figure(figsize=(8,6))\n",
    "pylab.scatter(map(lambda x: x[0], classification_problem[0]), map(lambda x: x[1], classification_problem[0]), \n",
    "              c=classification_problem[1], cmap=colors, s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(classification_problem[0], \n",
    "                                                                                     classification_problem[1], \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделяющая поверхность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meshgrid(data, step=.05, border=.5,):\n",
    "    x_min, x_max = data[:, 0].min() - border, data[:, 0].max() + border\n",
    "    y_min, y_max = data[:, 1].min() - border, data[:, 1].max() + border\n",
    "    return np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_surface(estimator, train_data, train_labels, test_data, test_labels, \n",
    "                          colors = colors, light_colors = light_colors):\n",
    "    #fit model\n",
    "    estimator.fit(train_data, train_labels)\n",
    "    \n",
    "    #set figure size\n",
    "    pyplot.figure(figsize = (16, 6))\n",
    "    \n",
    "    #plot decision surface on the train data \n",
    "    pyplot.subplot(1,2,1)\n",
    "    xx, yy = get_meshgrid(train_data)\n",
    "    mesh_predictions = np.array(estimator.predict(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n",
    "    pyplot.pcolormesh(xx, yy, mesh_predictions, cmap = light_colors)\n",
    "    pyplot.scatter(train_data[:, 0], train_data[:, 1], c = train_labels, s = 100, cmap = colors)\n",
    "    pyplot.title('Train data, accuracy={:.2f}'.format(metrics.accuracy_score(train_labels, estimator.predict(train_data))))\n",
    "    \n",
    "    #plot decision surface on the test data\n",
    "    pyplot.subplot(1,2,2)\n",
    "    pyplot.pcolormesh(xx, yy, mesh_predictions, cmap = light_colors)\n",
    "    pyplot.scatter(test_data[:, 0], test_data[:, 1], c = test_labels, s = 100, cmap = colors)\n",
    "    pyplot.title('Test data, accuracy={:.2f}'.format(metrics.accuracy_score(test_labels, estimator.predict(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = tree.DecisionTreeClassifier(random_state = 1, max_depth = 1)\n",
    "\n",
    "plot_decision_surface(estimator, train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree.DecisionTreeClassifier(random_state = 1, max_depth = 2),\n",
    "                      train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree.DecisionTreeClassifier(random_state = 1, max_depth = 3),\n",
    "                      train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree.DecisionTreeClassifier(random_state = 1),\n",
    "                      train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_decision_surface(tree.DecisionTreeClassifier(random_state = 1, min_samples_leaf = 3), \n",
    "                      train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;TIME&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;VOLUME&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30000</td>\n",
       "      <td>968.29</td>\n",
       "      <td>968.29</td>\n",
       "      <td>968.29</td>\n",
       "      <td>968.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30100</td>\n",
       "      <td>968.29</td>\n",
       "      <td>968.76</td>\n",
       "      <td>968.49</td>\n",
       "      <td>968.70</td>\n",
       "      <td>12993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30200</td>\n",
       "      <td>968.70</td>\n",
       "      <td>968.70</td>\n",
       "      <td>967.20</td>\n",
       "      <td>968.43</td>\n",
       "      <td>73800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30300</td>\n",
       "      <td>968.43</td>\n",
       "      <td>968.00</td>\n",
       "      <td>967.21</td>\n",
       "      <td>967.21</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30400</td>\n",
       "      <td>967.21</td>\n",
       "      <td>967.21</td>\n",
       "      <td>966.74</td>\n",
       "      <td>966.97</td>\n",
       "      <td>15969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30500</td>\n",
       "      <td>966.97</td>\n",
       "      <td>966.97</td>\n",
       "      <td>966.97</td>\n",
       "      <td>966.97</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30600</td>\n",
       "      <td>966.97</td>\n",
       "      <td>967.00</td>\n",
       "      <td>967.00</td>\n",
       "      <td>967.00</td>\n",
       "      <td>13231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30700</td>\n",
       "      <td>967.00</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30800</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20170101</td>\n",
       "      <td>30900</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31000</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31100</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31200</td>\n",
       "      <td>966.89</td>\n",
       "      <td>966.64</td>\n",
       "      <td>966.05</td>\n",
       "      <td>966.05</td>\n",
       "      <td>12900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31300</td>\n",
       "      <td>966.05</td>\n",
       "      <td>965.86</td>\n",
       "      <td>964.99</td>\n",
       "      <td>965.00</td>\n",
       "      <td>103237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31400</td>\n",
       "      <td>965.00</td>\n",
       "      <td>965.00</td>\n",
       "      <td>965.00</td>\n",
       "      <td>965.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31500</td>\n",
       "      <td>965.00</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.86</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31600</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31700</td>\n",
       "      <td>964.86</td>\n",
       "      <td>964.99</td>\n",
       "      <td>964.99</td>\n",
       "      <td>964.99</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31800</td>\n",
       "      <td>964.99</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20170101</td>\n",
       "      <td>31900</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32000</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32100</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32200</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32300</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32400</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32500</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32600</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>964.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32700</td>\n",
       "      <td>964.80</td>\n",
       "      <td>965.09</td>\n",
       "      <td>965.08</td>\n",
       "      <td>965.08</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32800</td>\n",
       "      <td>965.08</td>\n",
       "      <td>964.78</td>\n",
       "      <td>964.54</td>\n",
       "      <td>964.54</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20170101</td>\n",
       "      <td>32900</td>\n",
       "      <td>964.54</td>\n",
       "      <td>964.54</td>\n",
       "      <td>964.54</td>\n",
       "      <td>964.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607470</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233000</td>\n",
       "      <td>10204.50</td>\n",
       "      <td>10212.50</td>\n",
       "      <td>10199.00</td>\n",
       "      <td>10199.50</td>\n",
       "      <td>691901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607471</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233100</td>\n",
       "      <td>10199.50</td>\n",
       "      <td>10199.00</td>\n",
       "      <td>10188.50</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>1129081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607472</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233200</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>10199.00</td>\n",
       "      <td>10196.00</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>365740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607473</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233300</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>10189.00</td>\n",
       "      <td>10189.00</td>\n",
       "      <td>849636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607474</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233400</td>\n",
       "      <td>10189.00</td>\n",
       "      <td>10193.00</td>\n",
       "      <td>10189.00</td>\n",
       "      <td>10193.00</td>\n",
       "      <td>521571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607475</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233500</td>\n",
       "      <td>10193.00</td>\n",
       "      <td>10193.00</td>\n",
       "      <td>10181.50</td>\n",
       "      <td>10182.00</td>\n",
       "      <td>2082621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607476</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233600</td>\n",
       "      <td>10182.00</td>\n",
       "      <td>10190.00</td>\n",
       "      <td>10181.50</td>\n",
       "      <td>10189.50</td>\n",
       "      <td>763030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607477</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233700</td>\n",
       "      <td>10189.50</td>\n",
       "      <td>10196.00</td>\n",
       "      <td>10188.00</td>\n",
       "      <td>10196.00</td>\n",
       "      <td>747262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607478</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233800</td>\n",
       "      <td>10196.00</td>\n",
       "      <td>10234.00</td>\n",
       "      <td>10196.50</td>\n",
       "      <td>10234.00</td>\n",
       "      <td>2498730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607479</th>\n",
       "      <td>20180226</td>\n",
       "      <td>233900</td>\n",
       "      <td>10234.00</td>\n",
       "      <td>10240.00</td>\n",
       "      <td>10216.50</td>\n",
       "      <td>10234.50</td>\n",
       "      <td>1728232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607480</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234000</td>\n",
       "      <td>10234.50</td>\n",
       "      <td>10234.50</td>\n",
       "      <td>10225.00</td>\n",
       "      <td>10228.50</td>\n",
       "      <td>2024893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607481</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234100</td>\n",
       "      <td>10228.50</td>\n",
       "      <td>10229.00</td>\n",
       "      <td>10221.00</td>\n",
       "      <td>10229.00</td>\n",
       "      <td>1083855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607482</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234200</td>\n",
       "      <td>10229.00</td>\n",
       "      <td>10264.00</td>\n",
       "      <td>10228.50</td>\n",
       "      <td>10257.50</td>\n",
       "      <td>3398523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607483</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234300</td>\n",
       "      <td>10257.50</td>\n",
       "      <td>10263.00</td>\n",
       "      <td>10248.50</td>\n",
       "      <td>10258.50</td>\n",
       "      <td>2639318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607484</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234400</td>\n",
       "      <td>10258.50</td>\n",
       "      <td>10260.00</td>\n",
       "      <td>10250.00</td>\n",
       "      <td>10251.00</td>\n",
       "      <td>1703970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607485</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234500</td>\n",
       "      <td>10251.00</td>\n",
       "      <td>10251.00</td>\n",
       "      <td>10248.00</td>\n",
       "      <td>10248.00</td>\n",
       "      <td>963329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607486</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234600</td>\n",
       "      <td>10248.00</td>\n",
       "      <td>10248.50</td>\n",
       "      <td>10248.00</td>\n",
       "      <td>10248.50</td>\n",
       "      <td>720934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607487</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234700</td>\n",
       "      <td>10248.50</td>\n",
       "      <td>10257.00</td>\n",
       "      <td>10248.00</td>\n",
       "      <td>10257.00</td>\n",
       "      <td>1178009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607488</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234800</td>\n",
       "      <td>10257.00</td>\n",
       "      <td>10296.00</td>\n",
       "      <td>10257.00</td>\n",
       "      <td>10291.00</td>\n",
       "      <td>3654938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607489</th>\n",
       "      <td>20180226</td>\n",
       "      <td>234900</td>\n",
       "      <td>10291.00</td>\n",
       "      <td>10291.00</td>\n",
       "      <td>10280.50</td>\n",
       "      <td>10281.00</td>\n",
       "      <td>1655803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607490</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235000</td>\n",
       "      <td>10281.00</td>\n",
       "      <td>10289.00</td>\n",
       "      <td>10256.00</td>\n",
       "      <td>10261.50</td>\n",
       "      <td>1742596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607491</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235100</td>\n",
       "      <td>10261.50</td>\n",
       "      <td>10286.00</td>\n",
       "      <td>10256.00</td>\n",
       "      <td>10275.00</td>\n",
       "      <td>1426661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607492</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235200</td>\n",
       "      <td>10275.00</td>\n",
       "      <td>10275.50</td>\n",
       "      <td>10271.00</td>\n",
       "      <td>10271.00</td>\n",
       "      <td>422279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607493</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235300</td>\n",
       "      <td>10271.00</td>\n",
       "      <td>10270.50</td>\n",
       "      <td>10254.00</td>\n",
       "      <td>10264.50</td>\n",
       "      <td>1646508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607494</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235400</td>\n",
       "      <td>10264.50</td>\n",
       "      <td>10265.00</td>\n",
       "      <td>10253.00</td>\n",
       "      <td>10253.00</td>\n",
       "      <td>990036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607495</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235500</td>\n",
       "      <td>10253.00</td>\n",
       "      <td>10265.00</td>\n",
       "      <td>10253.00</td>\n",
       "      <td>10264.50</td>\n",
       "      <td>395347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607496</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235600</td>\n",
       "      <td>10264.50</td>\n",
       "      <td>10274.00</td>\n",
       "      <td>10264.50</td>\n",
       "      <td>10273.50</td>\n",
       "      <td>796567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607497</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235700</td>\n",
       "      <td>10273.50</td>\n",
       "      <td>10274.00</td>\n",
       "      <td>10264.00</td>\n",
       "      <td>10264.00</td>\n",
       "      <td>491170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607498</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235800</td>\n",
       "      <td>10264.00</td>\n",
       "      <td>10289.00</td>\n",
       "      <td>10264.00</td>\n",
       "      <td>10288.50</td>\n",
       "      <td>1860074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607499</th>\n",
       "      <td>20180226</td>\n",
       "      <td>235900</td>\n",
       "      <td>10288.50</td>\n",
       "      <td>10294.00</td>\n",
       "      <td>10281.00</td>\n",
       "      <td>10293.50</td>\n",
       "      <td>1987946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          <DATE>  <TIME>    <OPEN>    <HIGH>     <LOW>   <CLOSE>   <VOLUME>\n",
       "0       20170101   30000    968.29    968.29    968.29    968.29        0.0\n",
       "1       20170101   30100    968.29    968.76    968.49    968.70    12993.0\n",
       "2       20170101   30200    968.70    968.70    967.20    968.43    73800.0\n",
       "3       20170101   30300    968.43    968.00    967.21    967.21     3500.0\n",
       "4       20170101   30400    967.21    967.21    966.74    966.97    15969.0\n",
       "5       20170101   30500    966.97    966.97    966.97    966.97      300.0\n",
       "6       20170101   30600    966.97    967.00    967.00    967.00    13231.0\n",
       "7       20170101   30700    967.00    966.89    966.89    966.89      500.0\n",
       "8       20170101   30800    966.89    966.89    966.89    966.89        0.0\n",
       "9       20170101   30900    966.89    966.89    966.89    966.89        0.0\n",
       "10      20170101   31000    966.89    966.89    966.89    966.89        0.0\n",
       "11      20170101   31100    966.89    966.89    966.89    966.89        0.0\n",
       "12      20170101   31200    966.89    966.64    966.05    966.05    12900.0\n",
       "13      20170101   31300    966.05    965.86    964.99    965.00   103237.0\n",
       "14      20170101   31400    965.00    965.00    965.00    965.00        0.0\n",
       "15      20170101   31500    965.00    964.86    964.86    964.86     8000.0\n",
       "16      20170101   31600    964.86    964.86    964.86    964.86        0.0\n",
       "17      20170101   31700    964.86    964.99    964.99    964.99     3000.0\n",
       "18      20170101   31800    964.99    964.80    964.80    964.80        1.0\n",
       "19      20170101   31900    964.80    964.80    964.80    964.80        0.0\n",
       "20      20170101   32000    964.80    964.80    964.80    964.80        0.0\n",
       "21      20170101   32100    964.80    964.80    964.80    964.80        0.0\n",
       "22      20170101   32200    964.80    964.80    964.80    964.80        0.0\n",
       "23      20170101   32300    964.80    964.80    964.80    964.80        0.0\n",
       "24      20170101   32400    964.80    964.80    964.80    964.80        0.0\n",
       "25      20170101   32500    964.80    964.80    964.80    964.80        0.0\n",
       "26      20170101   32600    964.80    964.80    964.80    964.80        0.0\n",
       "27      20170101   32700    964.80    965.09    965.08    965.08     5000.0\n",
       "28      20170101   32800    965.08    964.78    964.54    964.54    35000.0\n",
       "29      20170101   32900    964.54    964.54    964.54    964.54        0.0\n",
       "...          ...     ...       ...       ...       ...       ...        ...\n",
       "607470  20180226  233000  10204.50  10212.50  10199.00  10199.50   691901.0\n",
       "607471  20180226  233100  10199.50  10199.00  10188.50  10196.50  1129081.0\n",
       "607472  20180226  233200  10196.50  10199.00  10196.00  10196.50   365740.0\n",
       "607473  20180226  233300  10196.50  10196.50  10189.00  10189.00   849636.0\n",
       "607474  20180226  233400  10189.00  10193.00  10189.00  10193.00   521571.0\n",
       "607475  20180226  233500  10193.00  10193.00  10181.50  10182.00  2082621.0\n",
       "607476  20180226  233600  10182.00  10190.00  10181.50  10189.50   763030.0\n",
       "607477  20180226  233700  10189.50  10196.00  10188.00  10196.00   747262.0\n",
       "607478  20180226  233800  10196.00  10234.00  10196.50  10234.00  2498730.0\n",
       "607479  20180226  233900  10234.00  10240.00  10216.50  10234.50  1728232.0\n",
       "607480  20180226  234000  10234.50  10234.50  10225.00  10228.50  2024893.0\n",
       "607481  20180226  234100  10228.50  10229.00  10221.00  10229.00  1083855.0\n",
       "607482  20180226  234200  10229.00  10264.00  10228.50  10257.50  3398523.0\n",
       "607483  20180226  234300  10257.50  10263.00  10248.50  10258.50  2639318.0\n",
       "607484  20180226  234400  10258.50  10260.00  10250.00  10251.00  1703970.0\n",
       "607485  20180226  234500  10251.00  10251.00  10248.00  10248.00   963329.0\n",
       "607486  20180226  234600  10248.00  10248.50  10248.00  10248.50   720934.0\n",
       "607487  20180226  234700  10248.50  10257.00  10248.00  10257.00  1178009.0\n",
       "607488  20180226  234800  10257.00  10296.00  10257.00  10291.00  3654938.0\n",
       "607489  20180226  234900  10291.00  10291.00  10280.50  10281.00  1655803.0\n",
       "607490  20180226  235000  10281.00  10289.00  10256.00  10261.50  1742596.0\n",
       "607491  20180226  235100  10261.50  10286.00  10256.00  10275.00  1426661.0\n",
       "607492  20180226  235200  10275.00  10275.50  10271.00  10271.00   422279.0\n",
       "607493  20180226  235300  10271.00  10270.50  10254.00  10264.50  1646508.0\n",
       "607494  20180226  235400  10264.50  10265.00  10253.00  10253.00   990036.0\n",
       "607495  20180226  235500  10253.00  10265.00  10253.00  10264.50   395347.0\n",
       "607496  20180226  235600  10264.50  10274.00  10264.50  10273.50   796567.0\n",
       "607497  20180226  235700  10273.50  10274.00  10264.00  10264.00   491170.0\n",
       "607498  20180226  235800  10264.00  10289.00  10264.00  10288.50  1860074.0\n",
       "607499  20180226  235900  10288.50  10294.00  10281.00  10293.50  1987946.0\n",
       "\n",
       "[607500 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = pd.read_csv('XBTUSD_20170101_20180226.csv')\n",
    "# beginnig in 20171215 8: 56 :00\n",
    "datas = datas.drop(['<TICKER>','<PER>'], axis =1)\n",
    "#pyplot.plot(np.linspace(0,100,106000),datas['<OPEN>'])\n",
    "#datas = datas.drop(range(0,5000), axis =0)\n",
    "datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# проценты от средней\n",
    "def mean_period(datas, pediod):\n",
    "    averages = []\n",
    "    for i in np.arange(period,datas.shape[0],period):\n",
    "        averages.append(datas['<OPEN>'][i-period:i].mean())\n",
    "    averages.append(datas['<OPEN>'][i:datas.shape[0]].mean())\n",
    "    return averages\n",
    "    \n",
    "def make_serias(datas,period,bound,averages):\n",
    "    current_price = datas['<OPEN>'][0]\n",
    "    result_serias = [] \n",
    "    #print(averages)\n",
    "    \n",
    "    for i in range(datas.shape[0]):\n",
    "        j = i / period\n",
    "        #print(j)\n",
    "        if current_price+averages[j]*bound/100.0<datas['<OPEN>'][i]:\n",
    "            current_price = current_price + averages[j]*bound/100.0\n",
    "            result_serias.append(-1)\n",
    "            \n",
    "        elif current_price - averages[j]*bound/100.0>datas['<OPEN>'][i]:\n",
    "            current_price = current_price - averages[j]*bound/100.0\n",
    "            result_serias.append(1)\n",
    "    return result_serias   \n",
    "\n",
    "\n",
    "\n",
    "def prob_a_z(serias):\n",
    "    a= 0 \n",
    "    z =0 \n",
    "    for i in range(len(serias)):\n",
    "        if serias[i] <0:\n",
    "            a = a+1\n",
    "        if serias[i]>0:\n",
    "            z = z+1\n",
    "    return {'success' : a,\n",
    "            'failure' : z,\n",
    "            'prob of success': float(a)/(a+z)}\n",
    "\n",
    "def make_past(serias,len_of_past):\n",
    "    data = []\n",
    "    y = []\n",
    "    for i in range(len_of_past,len(serias)):\n",
    "        data.append(serias[i - len_of_past:i])\n",
    "        y.append(serias[i])\n",
    "    return [np.array(data),np.array(y)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 5.0\n",
    "period = 60\n",
    "rounding = 1.0\n",
    "len_of_past = 10 \n",
    "serias = make_serias(datas,period,bound,mean_period(datas,period))\n",
    "prob_a_z(serias)\n",
    "data = make_past(serias,len_of_past)\n",
    "X = data[0]\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(X, \n",
    "                                                                                     y, test_size = 0.3,\n",
    "                                                                                     random_state = 0)\n",
    "\n",
    "# обучение :\n",
    "\n",
    "tree_class = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "tree_class.fit(train_data,train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542372881356\n",
      "0.489130434783\n",
      "0.569620253165\n"
     ]
    }
   ],
   "source": [
    "tree_class.feature_importances_\n",
    "print metrics.accuracy_score(test_labels,tree_class.predict(test_data))\n",
    "print metrics.precision_score(test_labels,tree_class.predict(test_data))\n",
    "print metrics.recall_score(test_labels,tree_class.predict(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1  1 -1 -1 -1 -1]\n",
      "[-1 -1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1  1  1  1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print test_labels[0:20]\n",
    "print tree_class.predict(test_data)[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_past = 100\n",
    "\n",
    "y = []\n",
    "X = [] \n",
    "\n",
    "i =5000 + len_of_past\n",
    "while i < datas.shape[0] :\n",
    "    y.append(datas['<OPEN>'][i])\n",
    "    X.append(list(datas['<OPEN>'][i-len_of_past-5000:i-5000-3])+list([np.array(datas['<VOLUME>'][i-len_of_past-5000:i-5000-10]).mean()]))\n",
    "    i+=1\n",
    "    \n",
    "X_all = np.array(X)\n",
    "y_all = np.array(y)\n",
    "\n",
    "#i = i =5000 + len_of_past\n",
    "#while i < datas.shape[0] :\n",
    "    #y.append(datas['<OPEN>'][i])\n",
    "    #X.append(list(datas['<OPEN>'][i-len_of_past-5000:i-5000-3])+list([np.array(datas['<VOLUME>'][i-len_of_past-5000:i-5000-10]).mean()]))\n",
    "    #i+=1\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data,y_train,y_test = train_test_split(X_all,y_all, test_size = 0.3,random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#обученное дерево\n",
    "scores = []\n",
    "depth = np.linspace(1,10,10)\n",
    "\n",
    "clf = ensemble.RandomForestRegressor(max_depth=20, random_state=2, n_estimators=200)\n",
    "clf.fit(train_data, y_train)\n",
    "predictions = clf.predict(test_data)\n",
    "#print predictions\n",
    "print clf.feature_importances_\n",
    "\n",
    "pyplot.plot(np.linspace(1,100,100),predictions[0:100])\n",
    "pyplot.plot(np.linspace(1,100,100),y_test[0:100])\n",
    "pyplot.show()\n",
    "print metrics.mean_absolute_error(y_test,predictions)/y_test.mean()\n",
    "print test_data\n",
    "print len(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions = clf.predict(X[500000:len(X)])\n",
    "print (predictions)\n",
    "pyplot.figure(figsize=(30,30))\n",
    "pyplot.plot(np.linspace(1,100,100),predictions[0:100], color = 'red')\n",
    "pyplot.plot(np.linspace(1,100,100),y[500000:500100])\n",
    "\n",
    "\n",
    "\n",
    "#predict_class = [ int(predictions[i-1]< predictions[i]) for i in range(1,len(predictions))]\n",
    "#y_test_1 = [int(y[i-1] <y[i]) for i in range(70001,len(X))]\n",
    "predict_class = []\n",
    "y_test_1 =[]\n",
    "for i in range(1,len(predictions)):\n",
    "    if predictions[i-1]< predictions[i]:\n",
    "        predict_class.append(2)\n",
    "    if predictions[i-1]== predictions[i]:\n",
    "        predict_class.append(1)\n",
    "    if predictions[i-1]>predictions[i]:\n",
    "        predict_class.append(0)\n",
    "        \n",
    "    if y[i-1+500000]<y[i+500000]:\n",
    "        y_test_1.append(2)\n",
    "    if y[i-1+500000]==y[i+500000]:\n",
    "        y_test_1.append(1)\n",
    "    if y[i-1+500000]>y[i+500000]:\n",
    "        y_test_1.append(0)\n",
    "\n",
    "#print metrics.accuracy_score(predict_class,y_test_1)\n",
    "#print metrics.precision_score(predict_class,y_test_1)\n",
    "#print metrics.recall_score(predict_class,y_test_1)\n",
    "tp1 = 0\n",
    "fp1 =0\n",
    "#print y_test_1\n",
    "\n",
    "\n",
    "#print predict_class\n",
    "#print y_test_1\n",
    "for i in range(len(predict_class)):\n",
    "    if predict_class[i] == 2:\n",
    "        if predict_class[i] == y_test_1[i]:\n",
    "            tp1+=1\n",
    "        if y_test_1[i] == 0:\n",
    "            fp1+=1\n",
    "        \n",
    "        \n",
    "print float(tp1)/(fp1+tp1)\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print p,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
